{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e7977dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /home/kara/anaconda3/lib/python3.8/site-packages (4.0.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/kara/anaconda3/lib/python3.8/site-packages (from gensim) (1.19.5)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from gensim) (3.0.0)\n",
      "Requirement already satisfied: requests in /home/kara/anaconda3/lib/python3.8/site-packages (from smart-open>=1.8.1->gensim) (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->smart-open>=1.8.1->gensim) (1.26.4)\n",
      "Requirement already satisfied: transformers in /home/kara/anaconda3/lib/python3.8/site-packages (4.7.0)\n",
      "Requirement already satisfied: sacremoses in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: filelock in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (0.0.8)\n",
      "Requirement already satisfied: pyyaml in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /home/kara/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /home/kara/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /home/kara/anaconda3/lib/python3.8/site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: torch in /home/kara/anaconda3/lib/python3.8/site-packages (1.9.0)\n",
      "Requirement already satisfied: typing-extensions in /home/kara/anaconda3/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: keras in /home/kara/anaconda3/lib/python3.8/site-packages (2.4.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from keras) (1.19.5)\n",
      "Requirement already satisfied: h5py in /home/kara/anaconda3/lib/python3.8/site-packages (from keras) (3.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/kara/anaconda3/lib/python3.8/site-packages (from keras) (5.4.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/kara/anaconda3/lib/python3.8/site-packages (from keras) (1.6.2)\n",
      "Requirement already satisfied: tensorflow in /home/kara/anaconda3/lib/python3.8/site-packages (2.5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.32.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from tensorboard~=2.5->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.2.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kara/anaconda3/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/kara/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: spacy in /home/kara/anaconda3/lib/python3.8/site-packages (3.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (0.5.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (1.7.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (2.4.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (8.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: jinja2 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /home/kara/anaconda3/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (3.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kara/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /home/kara/anaconda3/lib/python3.8/site-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/kara/anaconda3/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Requirement already satisfied: xgboost in /home/kara/anaconda3/lib/python3.8/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy in /home/kara/anaconda3/lib/python3.8/site-packages (from xgboost) (1.19.5)\n",
      "Requirement already satisfied: scipy in /home/kara/anaconda3/lib/python3.8/site-packages (from xgboost) (1.6.2)\n",
      "Requirement already satisfied: NlpToolkit-DependencyParser in /home/kara/anaconda3/lib/python3.8/site-packages (1.0.14)\n",
      "Requirement already satisfied: NlpToolkit-MorphologicalAnalysis in /home/kara/anaconda3/lib/python3.8/site-packages (from NlpToolkit-DependencyParser) (1.0.32)\n",
      "Requirement already satisfied: NlpToolkit-DataStructure in /home/kara/anaconda3/lib/python3.8/site-packages (from NlpToolkit-MorphologicalAnalysis->NlpToolkit-DependencyParser) (1.0.9)\n",
      "Requirement already satisfied: NlpToolkit-Corpus in /home/kara/anaconda3/lib/python3.8/site-packages (from NlpToolkit-MorphologicalAnalysis->NlpToolkit-DependencyParser) (1.0.11)\n",
      "Requirement already satisfied: NlpToolkit-Dictionary in /home/kara/anaconda3/lib/python3.8/site-packages (from NlpToolkit-MorphologicalAnalysis->NlpToolkit-DependencyParser) (1.0.20)\n",
      "Requirement already satisfied: NlpToolkit-Math in /home/kara/anaconda3/lib/python3.8/site-packages (from NlpToolkit-Dictionary->NlpToolkit-MorphologicalAnalysis->NlpToolkit-DependencyParser) (1.0.13)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "!pip install spacy\n",
    "!pip install xgboost\n",
    "!pip3 install NlpToolkit-DependencyParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e52e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import extract_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "\n",
    "import nltk\n",
    "\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.tr import Turkish\n",
    "\n",
    "import logging\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed6a2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = extract_data(os.getcwd()+\"/Datasets/train_data.xml\")\n",
    "x_test = extract_data(os.getcwd()+\"/Datasets/test_data.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba3dfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of                                                Reviews                Aspects  \\\n",
       "0                bu servise bu fiyatlar ise cok faZla.               fiyatlar   \n",
       "1    Lacivert beni kalitesinin dusukluguyle cok sas...            kalitesinin   \n",
       "2    Buraya bu kadar iyi yorum yapanlar her halde d...                  balik   \n",
       "3    Kalamardan ve koladan önce balik geldi ve apar...            balik geldi   \n",
       "4        ayrica gelen kalamar soguk ve sünger gibiydi.                kalamar   \n",
       "..                                                 ...                    ...   \n",
       "785      Arka bahçesi tüm yorgunluğunu alıyor insanın.           Arka bahçesi   \n",
       "786                          Yer bulmak da zor oluyor.             Yer bulmak   \n",
       "787  İngiliz cayi istedigimde sut getirmediler gere...                 garson   \n",
       "788  Ayrıca hergun çıkardıkları farklı zeytinyağlı ...  zeytinyağlı yemekleri   \n",
       "789        Fiyatlar ortalamanın biraz ustunde malesef.               Fiyatlar   \n",
       "\n",
       "    Sentiment  \n",
       "0    negative  \n",
       "1    negative  \n",
       "2    negative  \n",
       "3    negative  \n",
       "4    negative  \n",
       "..        ...  \n",
       "785  positive  \n",
       "786  negative  \n",
       "787  negative  \n",
       "788  positive  \n",
       "789  negative  \n",
       "\n",
       "[790 rows x 3 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_train = [review for review, aspects in x_train.items() if (len(aspects) == 1)]\n",
    "aspect_train = [aspects[0][0] for review, aspects in x_train.items() if (len(aspects) == 1)]\n",
    "sentiment_train = [aspects[0][1] for review, aspects in x_train.items() if (len(aspects) == 1)]\n",
    "single_train = {\"Reviews\": text_train, \"Aspects\": aspect_train, \"Sentiment\": sentiment_train}\n",
    "df_train = pd.DataFrame(single_train)\n",
    "df_train.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d47418d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bu servise bu fiyatlar ise cok faZla.\n"
     ]
    }
   ],
   "source": [
    "from DependencyParser.Turkish.TurkishDependencyRelation import DependencyRelation\n",
    "\n",
    "parser = DependencyRelation(text_train[0]).to()\n",
    "print(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e2c24ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('trmodel', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "83edd64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\"negative\": 0, \"neutral\":1, \"positive\": 2}\n",
    "X_train = []\n",
    "y_train = [mapping[sent] for sent in sentiment_train]\n",
    "nlp = Turkish()\n",
    "def feature_extraction(text):\n",
    "    vector = np.zeros(400)\n",
    "    for token in nlp(text.lower()):\n",
    "        word = token.text.lower()\n",
    "        if word in word_vectors:\n",
    "            vector+=word_vectors[word]\n",
    "    return vector\n",
    "\n",
    "for review in text_train:\n",
    "    X_train.append(feature_extraction(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d27c1b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_test = [review for review, aspects in x_test.items() if (len(aspects) == 1)]\n",
    "aspects_test = [aspects[0][0] for review, aspects in x_test.items() if (len(aspects) == 1)]\n",
    "sentiment_test = [aspects[0][1] for review, aspects in x_test.items() if (len(aspects) == 1)]\n",
    "single_test = {\"Reviews\": text_test, \"Aspects\": aspects_test, \"Sentiment\": sentiment_test}\n",
    "df_test = pd.DataFrame(single_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f05dc825",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = [mapping[sent] for sent in sentiment_test]\n",
    "nlp = Turkish()\n",
    "def feature_extraction(text):\n",
    "    vector = np.zeros(400)\n",
    "    print(nlp(text.lower()))\n",
    "    for token in nlp(text.lower()):\n",
    "        word = token.text.lower()\n",
    "        if word in word_vectors:\n",
    "            vector+=word_vectors[word]\n",
    "    return vector\n",
    "\n",
    "for review in text_test:\n",
    "    X_test.append(feature_extraction(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bcdc1bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM Attempts\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X_train, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d50c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_pred = linear.predict(X_test)\n",
    "poly_pred = poly.predict(X_test)\n",
    "rbf_pred = rbf.predict(X_test)\n",
    "sig_pred = sig.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3553deca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of Linear Kernel: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53        28\n",
      "           1       0.11      0.25      0.15         4\n",
      "           2       0.85      0.59      0.70        68\n",
      "\n",
      "    accuracy                           0.60       100\n",
      "   macro avg       0.46      0.51      0.46       100\n",
      "weighted avg       0.70      0.60      0.63       100\n",
      "\n",
      "Classification Report of Polynomial Kernel: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.29      0.37        28\n",
      "           1       0.33      0.25      0.29         4\n",
      "           2       0.72      0.87      0.79        68\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.53      0.47      0.48       100\n",
      "weighted avg       0.65      0.68      0.65       100\n",
      "\n",
      "Classification Report of RBF Kernel: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        28\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.68      1.00      0.81        68\n",
      "\n",
      "    accuracy                           0.68       100\n",
      "   macro avg       0.23      0.33      0.27       100\n",
      "weighted avg       0.46      0.68      0.55       100\n",
      "\n",
      "Classification Report of Sigmoid Kernel: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.50      0.39        28\n",
      "           1       0.00      0.00      0.00         4\n",
      "           2       0.71      0.59      0.65        68\n",
      "\n",
      "    accuracy                           0.54       100\n",
      "   macro avg       0.34      0.36      0.34       100\n",
      "weighted avg       0.57      0.54      0.55       100\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_lin = linear.score(X_test, y_test)\n",
    "accuracy_poly = poly.score(X_test, y_test)\n",
    "accuracy_rbf = rbf.score(X_test, y_test)\n",
    "accuracy_sig = sig.score(X_test, y_test)\n",
    "\n",
    "print(\"Classification Report of Linear Kernel: \\n\", classification_report(y_test,linear_pred))\n",
    "print(\"Classification Report of Polynomial Kernel: \\n\",classification_report(y_test,poly_pred))\n",
    "print(\"Classification Report of RBF Kernel: \\n\",classification_report(y_test,rbf_pred))\n",
    "print(\"Classification Report of Sigmoid Kernel: \\n\",classification_report(y_test,sig_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "28f59afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kara/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/home/kara/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:09:51] WARNING: ../src/learner.cc:573: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[13:09:51] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-4fa42948f7b7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mgsearch1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_cl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "xgb_cl = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'multi:softmax',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb_cl, param_grid = param_test1, scoring='roc_auc',n_jobs=4, cv=5)\n",
    "gsearch1.fit(np.array(X_train),np.array(y_train))\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "80194eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report of XGBoost with Softmax: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        28\n",
      "           1       0.33      0.25      0.29         4\n",
      "           2       0.77      0.74      0.75        68\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.51      0.50      0.50       100\n",
      "weighted avg       0.66      0.65      0.65       100\n",
      "\n",
      "Classification Report of XGBoost with Softprob: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.50      0.47        28\n",
      "           1       0.33      0.25      0.29         4\n",
      "           2       0.77      0.74      0.75        68\n",
      "\n",
      "    accuracy                           0.65       100\n",
      "   macro avg       0.51      0.50      0.50       100\n",
      "weighted avg       0.66      0.65      0.65       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report of XGBoost with Softmax: \\n\", classification_report(y_test,xgb_softmax_pred))\n",
    "print(\"Classification Report of XGBoost with Softprob: \\n\", classification_report(y_test,xgb_softprob_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187010e7",
   "metadata": {},
   "source": [
    "## Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b64883b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU available, using the CPU instead.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b0b2ccda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(text):\n",
    "    x = tokenizer.encode(filter(text))\n",
    "    with torch.no_grad():\n",
    "        x, _ = bert(torch.stack([torch.tensor(x)]).to(device))\n",
    "        return list(x[0][0].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b30dc17c",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "filter expected 2 arguments, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-151-5fc5e601b94a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-141-e97b33fa40b4>\u001b[0m in \u001b[0;36mfeature_extraction\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeature_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: filter expected 2 arguments, got 1"
     ]
    }
   ],
   "source": [
    "print(feature_extraction(text_train[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab0706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
